{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "239ea8b1-4081-41b8-b972-bb8262533cb5",
   "metadata": {},
   "source": [
    "# Data Science for Social Justice Workshop: Word Embeddings and Language Bias - PROJECT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b228ca92-c535-46c6-85c6-b397dc95b218",
   "metadata": {},
   "source": [
    "### Icons Used in This Notebook\n",
    "ðŸ’­ **Reflection**: Reflecting on ethical implications, biases, and social impact in data science.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5132915b-031e-4a0b-a9e5-d2b399864384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "from gensim.models import Word2Vec\n",
    "import multiprocessing\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a4f7a0-8d78-44c0-8b27-5015178a2ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace this with your own pickle file!\n",
    "with open('../../data/YOUR_FILE.pickle', 'rb') as f:\n",
    "    posts = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b980b67-4391-481f-bd2e-781b7255ed71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split into lists of words for Word2Vec\n",
    "post_list = [post.split() for post in posts]\n",
    "post_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d88d4c-38a4-4ea3-a61e-7253b389ee8a",
   "metadata": {
    "id": "Wk2mxX1HZOpk"
   },
   "source": [
    "# Constructing a Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37503c4-1a2b-4a52-942a-a61c8a47ae0c",
   "metadata": {
    "id": "sQq117-pZOpl"
   },
   "outputs": [],
   "source": [
    "cores = multiprocessing.cpu_count() # Number of cores at your disposal\n",
    "\n",
    "n_features = 300     # Word vector dimensionality (how many features each word will be given)\n",
    "min_word_count = 10  # Minimum word count to be taken into account\n",
    "n_workers = cores    # Number of threads to run in parallel (equal to your amount of cores)\n",
    "window = 5           # Context window size\n",
    "downsampling = 1e-2  # Downsample setting for frequent words\n",
    "seed = 1             # Seed for the random number generator (to create reproducible results)\n",
    "sg = 1               # Skip-gram = 1, CBOW = 0\n",
    "epochs = 20          # Number of iterations over the corpus\n",
    "\n",
    "model = Word2Vec(\n",
    "    sentences=post_list,\n",
    "    workers=n_workers,\n",
    "    vector_size=n_features,\n",
    "    min_count=min_word_count,\n",
    "    window=window,\n",
    "    sample=downsampling,\n",
    "    seed=seed,\n",
    "    sg=sg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27457c86-4324-4a78-a2e1-192716a4d21a",
   "metadata": {
    "id": "JRX-lzwSzFI5"
   },
   "outputs": [],
   "source": [
    "# Save the model to disk\n",
    "model.save('../../data/embeddings.emb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37eb26f-924e-41b5-ae2e-c6d6817b3959",
   "metadata": {
    "id": "SZMDwWBuGTn7"
   },
   "outputs": [],
   "source": [
    "# Load the model from disk\n",
    "model = Word2Vec.load('../../data/embeddings.emb')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8032c3-401d-467d-90ad-9f6ee5285331",
   "metadata": {
    "id": "wWQC4S9IZOpu"
   },
   "source": [
    "How many terms are in your vocabulary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b998475-0cee-4a9d-87fa-4397d2bf4e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model.wv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14436cc-0c76-429e-a080-01b8806d953a",
   "metadata": {},
   "source": [
    "# Word Similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01c7e85-d9a1-49b2-96aa-f83a860edb80",
   "metadata": {
    "id": "v1HVouFqZOp0"
   },
   "outputs": [],
   "source": [
    "def get_most_similar_terms(model, token, topn=20):\n",
    "    \"\"\"Look up the top N most similar terms to the token.\"\"\"\n",
    "    for word, similarity in model.wv.most_similar(positive=[token], topn=topn):\n",
    "        print(f\"{word}: {round(similarity, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e31bbf3-9190-451e-a842-21c5a6720530",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 304,
     "status": "ok",
     "timestamp": 1639950052918,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhuBmxDvW5I_LJfZtwlPqMFD8QGLVPP3skvpkTnuQ=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -60
    },
    "id": "CDyV-ntGZOp3",
    "outputId": "d72277e1-e4e1-451d-e706-70b7fb7ebb02"
   },
   "outputs": [],
   "source": [
    "get_most_similar_terms(model, 'CHOOSE_WORD')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed4fc94-dbb9-4384-8eb3-edacfb1e1f62",
   "metadata": {},
   "source": [
    "# Visualizing High Dimensional Spaces with $t$-SNE\n",
    "\n",
    "Change `words` to include words you are interested in for your data (make sure they appear in your dataset!) in order to visualize their relations. You can make this list as long or short as you want.\n",
    "\n",
    "ðŸ’­ **Reflection**: Figuring out **which words** you are interested in exploring is one of the main challenges when doing work like this! It will depends on your subreddit and your research questions. Discuss this with your group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd556fa-8fee-49bc-9589-05f9d7187914",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['WORD1', 'WORD2', 'WORD3', 'WORD4', 'WORD5', 'WORD6', 'WORD7', 'WORD8']\n",
    "\n",
    "# Extract the word vectors\n",
    "word_vectors = np.array([model.wv[word] for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab163662-038f-4a22-91c6-d3b71c5c5937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you get an ImportError in the line tsne=TSNE(), you might need to install scikit-learn:\n",
    "# %pip install -U scikit-learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6792fda-4bd6-414a-b275-75bf3352a80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce dimensionality using t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=2, perplexity=2)\n",
    "reduced_vectors = tsne.fit_transform(word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e15576-3c70-4d8b-962b-46f99a86c540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the t-SNE vectors\n",
    "words_df = pd.DataFrame(reduced_vectors,\n",
    "                            index=pd.Index([word for word in words]),\n",
    "                            columns=['x', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f96089c-a595-4eba-8eb8-c4af5d073574",
   "metadata": {
    "id": "9AE4-OrmKmKG"
   },
   "outputs": [],
   "source": [
    "import bokeh\n",
    "from bokeh.plotting import figure, show, output_notebook\n",
    "from bokeh.models import HoverTool, ColumnDataSource, LabelSet\n",
    "\n",
    "output_notebook()\n",
    "bokeh.io.output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c47ac40-66e9-4087-afa6-1c445a2daea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add our DataFrame as a ColumnDataSource for Bokeh\n",
    "plot_data = ColumnDataSource(words_df)\n",
    "\n",
    "# Create the plot and configure the title, dimensions, and tools\n",
    "tsne_plot = figure(title='t-SNE Word Embeddings')\n",
    "\n",
    "# Add a hover tool to display words on roll-over\n",
    "tsne_plot.add_tools(HoverTool(tooltips='@index'))\n",
    "\n",
    "# Draw the words as circles on the plot\n",
    "tsne_plot.circle('x', 'y',\n",
    "                 source=plot_data,\n",
    "                 color='blue',\n",
    "                 size=10,\n",
    "                 hover_line_color='black')\n",
    "\n",
    "# Add labels to the points\n",
    "labels = LabelSet(x='x', y='y', text='index', level='glyph',\n",
    "                  x_offset=5, y_offset=5, source=plot_data,\n",
    "                  render_mode='canvas')\n",
    "tsne_plot.add_layout(labels)\n",
    "\n",
    "# Engage!\n",
    "show(tsne_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72f6950-9ce6-464a-8e6b-5f36b980c134",
   "metadata": {},
   "source": [
    "Now let's use $t$-SNE to take **all** the word vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bb6125-b1bf-49ef-9ac2-a47e0f471b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(init='pca', learning_rate='auto')\n",
    "X_tsne = tsne.fit_transform(model.wv.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa375c4-1f59-44de-a91a-fbcf3a9ae63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the t-SNE vectors\n",
    "tsne_df = pd.DataFrame(X_tsne,\n",
    "                            index=pd.Index(model.wv.index_to_key),\n",
    "                            columns=['x', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9437ab84-d63b-4635-be70-932ed5d3ab73",
   "metadata": {
    "id": "jd60bqFxe9z1"
   },
   "outputs": [],
   "source": [
    "# Create some filepaths to save our model\n",
    "tsne_path = '../../data/tsne_model'\n",
    "tsne_df_path = '../../data/tsne_df.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87100b48-bd49-47ae-8272-be125f75f3ae",
   "metadata": {
    "id": "QBe7lNE3e7oQ"
   },
   "outputs": [],
   "source": [
    "# Save to disk\n",
    "with open(tsne_path, 'wb') as f:\n",
    "    pickle.dump(X_tsne, f)\n",
    "\n",
    "tsne_df.to_pickle(tsne_df_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af164a0-0697-4f73-9cd5-55fde33120d8",
   "metadata": {},
   "source": [
    "Here's a convenient code block to load this data, to start from this point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1934629a-c3c4-4c01-808e-00e6bbd81aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tsne_path, 'rb') as f:\n",
    "    X_tsne = pickle.load(f)\n",
    "    \n",
    "tsne_df = pd.read_pickle(tsne_df_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220e4008-202a-431e-a692-8b08c3a43f90",
   "metadata": {},
   "source": [
    "Visualize with `bokeh`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed097c8d-6d08-480d-8f0d-c63504529dce",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 817
    },
    "executionInfo": {
     "elapsed": 747,
     "status": "ok",
     "timestamp": 1640017607454,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhuBmxDvW5I_LJfZtwlPqMFD8QGLVPP3skvpkTnuQ=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -60
    },
    "id": "myJtActVdjn4",
    "outputId": "5f283a90-c0f4-4c31-88ea-5f7bfa6917ee",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add our DataFrame as a ColumnDataSource for Bokeh\n",
    "plot_data = ColumnDataSource(tsne_df)\n",
    "\n",
    "# Create the plot and configure the title, dimensions, and tools\n",
    "tsne_plot = figure(title='t-SNE Word Embeddings')\n",
    "\n",
    "# Add a hover tool to display words on roll-over\n",
    "tsne_plot.add_tools(HoverTool(tooltips='@index') )\n",
    "\n",
    "# Draw the words as circles on the plot\n",
    "tsne_plot.circle('x', 'y',\n",
    "                 source=plot_data,\n",
    "                 color='blue',\n",
    "                 line_alpha=0.2,\n",
    "                 fill_alpha=0.1,\n",
    "                 size=10,\n",
    "                 hover_line_color='black')\n",
    "\n",
    "# Engage!\n",
    "show(tsne_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bc6563-a2b7-430e-b5f1-94bebd7b975f",
   "metadata": {},
   "source": [
    "# Language Biases and Word Embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36bcc0a-09ca-48ba-b2d4-63569e82934c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import function to calculate biased words\n",
    "from utils import calculate_biased_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb562757-1cf9-4238-bc31-af332a29afae",
   "metadata": {},
   "source": [
    "ðŸ’­ **Reflection**: You will have to change the following words to words that are illustrative of a **target concept**, organized in some kind of binary. Think of \"male\" and \"female\", \"Islam\" and \"Christianity\", or \"career\" and \"family\". For some examples of target sets that have been used in the literature on language biases, check the [bottom of this notebook](#targets).\n",
    "\n",
    "Discuss with your teammates which concepts you would like to explore, and how you would define the target concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca51a4ab-b3f4-4cce-a19c-74465c5e03c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "target1 = ['WORD1' , 'WORD2' , 'WORD3' , 'WORD4' , 'WORD5' , 'WORD6' , 'WORD7' , 'WORD8']\n",
    "target2 = ['WORD1' , 'WORD2' , 'WORD3' , 'WORD4' , 'WORD5' , 'WORD6' , 'WORD7' , 'WORD8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659d51a9-c0fd-4492-849e-96c8cc3edd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load('../../data/embeddings.emb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83da73ef-e7fe-4494-bc0d-62e83cbfe7bd",
   "metadata": {
    "executionInfo": {
     "elapsed": 11526,
     "status": "ok",
     "timestamp": 1647303428120,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhuBmxDvW5I_LJfZtwlPqMFD8QGLVPP3skvpkTnuQ=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": 300
    },
    "id": "SIzdtQV5rQlh",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[b1, b2] = calculate_biased_words(model, target1, target2, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50fa880-09a7-4169-8991-b6cb17a7b7aa",
   "metadata": {
    "id": "LJpg5BDydlYT"
   },
   "source": [
    "Let's print some biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12349d29-3b4d-4865-8428-ee0ceff24d0f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 191,
     "status": "ok",
     "timestamp": 1647303438347,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhuBmxDvW5I_LJfZtwlPqMFD8QGLVPP3skvpkTnuQ=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": 300
    },
    "id": "qc-9g8BErQll",
    "outputId": "93aa1d97-e9ad-4f17-9ce3-bef7d4079209"
   },
   "outputs": [],
   "source": [
    "print('Biased words towards target set 1')\n",
    "print([word for word in b1.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca33e41e-bfc7-4be5-80bb-6e83f181c452",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Biased words towards target set 2')\n",
    "print([word for word in b2.keys()] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc812af-422c-446e-ad00-1cf743155101",
   "metadata": {
    "id": "Zpk0lx2xplMf"
   },
   "source": [
    "## Visualizing Biases using $t$-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7754fedb-2f16-450c-9d95-c12280b546e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b669be3e-2071-4714-a4c1-ffae8164579d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tsne_path, 'rb') as f:\n",
    "    X_tsne = pickle.load(f)\n",
    "    \n",
    "tsne_df = pd.read_pickle(tsne_df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af85d3bf-e8cb-4449-af36-bb3b729597fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert biased term keys to arrays\n",
    "target1_idx = np.array([model.wv.key_to_index[key] for key in b1.keys()])\n",
    "target2_idx = np.array([model.wv.key_to_index[key] for key in b2.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2494d6be-2276-4692-9e5f-e5d42655fbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find t-sne values for the biased sets\n",
    "X_target1 = X_tsne[target1_idx]\n",
    "X_target2 = X_tsne[target2_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6cea48-7caf-4f8b-aeed-bd4cc8c2458c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import show, output_notebook, output_file\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.models import ColumnDataSource, LabelSet\n",
    "\n",
    "# Set up the Bokeh plot\n",
    "output_notebook()\n",
    "\n",
    "p = figure()\n",
    "\n",
    "# Create ColumnDataSource for X_target1 (blue)\n",
    "source1 = ColumnDataSource(data=dict(x=X_target1[:, 0], y=X_target1[:, 1], label=[model.wv.index_to_key[idx] for idx in target1_idx]))\n",
    "\n",
    "# Create ColumnDataSource for X_target2 (red)\n",
    "source2 = ColumnDataSource(data=dict(x=X_target2[:, 0], y=X_target2[:, 1], label=[model.wv.index_to_key[idx] for idx in target2_idx]))\n",
    "\n",
    "# Add scatter plot for X_target1 (blue)\n",
    "p.scatter(x='x', y='y', color='blue', size=8, source=source1)\n",
    "\n",
    "# Add scatter plot for X_target2 (red)\n",
    "p.scatter(x='x', y='y', color='red', size=8, source=source2)\n",
    "\n",
    "# Add labels for X_target1\n",
    "labels1 = LabelSet(x='x', y='y', text='label', x_offset=6, y_offset=3, source=source1, render_mode='canvas')\n",
    "p.add_layout(labels1)\n",
    "\n",
    "# Add labels for X_target2\n",
    "labels2 = LabelSet(x='x', y='y', text='label', x_offset=6, y_offset=3, source=source2, render_mode='canvas')\n",
    "p.add_layout(labels2)\n",
    "\n",
    "# Show the plot\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d28f7c-648a-458a-8874-9e0c4a66d374",
   "metadata": {},
   "source": [
    "## ðŸ’­ Reflection\n",
    "\n",
    "Note that these binary target concepts are often a product of ideology and normativity in society: the gender binary is a good example. When checking for biases towards certain concepts, make sure you consider the fact that you are the one creating / reproducing these concepts, and that you may be reinforcing a constructed binary!\n",
    "\n",
    "Also note that determining your own target concepts and biases is a **iterative** process. Try changing some of the words in the target concepts to see how the biased words and plot change, and discuss with your group what you think makes for a coherent and robust target set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60527010-8a4e-477a-8513-c51c489bd4b5",
   "metadata": {
    "id": "riINX9wVyFRJ",
    "tags": []
   },
   "source": [
    "<a id='targets'></a>\n",
    "# Existing Target Sets\n",
    "\n",
    "Here are some other target sets that have been previously used in the literature:\n",
    "\n",
    "* *Gender target sets taken from Nosek, Banaji, and Greenwald 2002.*\n",
    "    - Female: `sister, female, woman, girl, daughter, she, hers, her`.\n",
    "    - Male: `brother, male, man, boy, son, he, his, him`.\n",
    "* *Religion target sets taken from Garg et al. 2018.*\n",
    "    - Islam: `allah, ramadan, turban, emir, salaam, sunni, koran, imam, sultan, prophet, veil, ayatollah, shiite, mosque, islam, sheik, muslim, muhammad`.\n",
    "    - Christianity: `baptism, messiah, catholicism, resurrection, christianity, salva-tion, protestant, gospel, trinity, jesus, christ, christian, cross,catholic, church`.\n",
    "* *Racial target sets taken from Garg et al. 2017*\n",
    "    - White last names: `harris, nelson, robinson, thompson, moore, wright, anderson, clark, jackson, taylor, scott, davis, allen, adams, lewis, williams, jones, wilson, martin, johnson`.\n",
    "    - Hispanic last names: `ruiz, alvarez, vargas, castillo, gomez, soto,gonzalez, sanchez, rivera, mendoza, martinez, torres, ro-driguez, perez, lopez, medina, diaz, garcia, castro, cruz`.\n",
    "    - Asian last names: `cho, wong, tang, huang, chu, chung, ng,wu, liu, chen, lin, yang, kim, chang, shah, wang, li, khan,singh, hong`.\n",
    "    - Russian last names: `gurin, minsky, sokolov, markov, maslow, novikoff, mishkin, smirnov, orloff, ivanov, sokoloff, davidoff, savin, romanoff, babinski, sorokin, levin, pavlov, rodin, agin`.\n",
    "* *Career/family target sets taken from Garg et al. 2018.*\n",
    "    - Career: `executive, management, professional, corporation, salary, office, business, career`.\n",
    "    - Family: `home, parents, children, family, cousins, marriage, wedding, relatives.Math: math, algebra, geometry, calculus, equations, computation, numbers, addition`.\n",
    "* *Arts/Science target sets taken from Garg et al. 2018.*\n",
    "    - Arts: `poetry, art, sculpture, dance, literature, novel, symphony, drama`.\n",
    "    - Science: `science, technology, physics, chemistry, Einstein, NASA, experiment, astronomy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e3acf0-3aab-40fa-b9a6-751af0baed35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
