{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WClw_VPOmwXd"
   },
   "source": [
    "# Data Science for Social Justice Workshop: Sentiment Analysis â€“ Project Notebook\n",
    "\n",
    "Use this notebook for carrying out the analyses from the workshop notebook on your own subreddit data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6erwYIhh-cR"
   },
   "source": [
    "## Import the Dataset\n",
    "\n",
    "On a subreddit like AITA, the manner in which the OP expresses sentiment on the involved parties influences how commenters interpret and ultimately vote on the situation. Expressions of sentiment reflect the norms carried by the community under study.\n",
    "\n",
    "Let's take a look at some example comments. First, we import the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/YOUR_FILE.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at example submissions. What is the sentiment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['selftext'].iloc[501])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['selftext'].iloc[200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['selftext'].iloc[750])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using VADER to Conduct Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the VADER SentimentIntensityAnalyzer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "# Create analyzer object\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(analyzer.polarity_scores(df['selftext'].iloc[501]))\n",
    "print(analyzer.polarity_scores(df['selftext'].iloc[200]))\n",
    "print(analyzer.polarity_scores(df['selftext'].iloc[750]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Characterizing Sentiment at Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of [removed] posts\n",
    "df_filtered = df[df['selftext'] != '[removed]'].copy()\n",
    "# Get rid of NA posts\n",
    "df_filtered = df_filtered[~df_filtered['selftext'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list to store scores\n",
    "compound_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This may take a few minutes to run\n",
    "\n",
    "# Iterate through the selftext of each post\n",
    "for post in df_filtered['selftext']:\n",
    "    # Calculate sentiment\n",
    "    sentiment = analyzer.polarity_scores(post)\n",
    "    # Store each score\n",
    "    compound_scores.append(sentiment['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the compound scores in the dataframe\n",
    "df_filtered['sentiment'] = compound_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the distribution of sentiment. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered['sentiment'].hist(grid=False)\n",
    "plt.xlabel('Compound Sentiment Score', fontsize=15)\n",
    "plt.ylabel('Frequency', fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does Post Score Correlate with Sentiment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binned_statistic\n",
    "import numpy as np\n",
    "\n",
    "def plot_score_vs_sentiment(sentiment, score, n_bins=9):\n",
    "    \"\"\"Plots the average score within ranges of sentiment values.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sentiment : pd.Series\n",
    "        The sentiment column from your dataframe.\n",
    "    score : pd.Series\n",
    "        The score column from your dataframe.\n",
    "    n_bins : int\n",
    "        The number of bins to plot.\n",
    "    \"\"\"\n",
    "    # Calculate binned sentiment values\n",
    "    bin_means, bin_edges, binnumber = binned_statistic(sentiment,\n",
    "                                                       score,\n",
    "                                                       statistic='mean',\n",
    "                                                       bins=np.linspace(-1, 1, n_bins))\n",
    "    # Calculate bin width of bar plot\n",
    "    binwidth = np.ediff1d(bin_edges)[0]\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "    ax.bar(x=bin_edges[:-1] + binwidth / 2, height=bin_means, width=binwidth)\n",
    "    ax.set_xlim([-1, 1])\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_score_vs_sentiment(df_filtered['sentiment'], df_filtered['score'], n_bins=10)\n",
    "plt.xlim([-1.05, 1.05])\n",
    "plt.ylim([5000, 6700])\n",
    "plt.xlabel('Compound Sentiment', fontsize=15)\n",
    "plt.ylabel('Average Post Score', fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We definitely observe a pattern: Posts with the most negative and most positive sentiment generally have higher scores!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŽ¬ Demo : Sentiment Analysis with spaCy and TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform these installs first\n",
    "%pip install textblob\n",
    "%pip install spacytextblob\n",
    "%python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import spacy\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create NLP object\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "# Important: we have to add textblob to our spaCy pipeline\n",
    "nlp.add_pipe('spacytextblob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the spaCy pipeline to each post\n",
    "# This command will take a while to run if your dataset is big\n",
    "docs = list(nlp.pipe(df_filtered['selftext']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TextBlob calculates sentiments in the variable \"polarity\". It also includes a variable called \"subjectivity\", which ranges from 0 to 1. It estimates the level of subjectivity expressed in the post (values closer to 1 are higher subjectivity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the polarities in a list\n",
    "polarities = []\n",
    "for doc in docs:\n",
    "    polarities.append(doc._.polarity)\n",
    "df_filtered['polarities'] = polarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the subjectivities in a list\n",
    "subjectivities = []\n",
    "for doc in docs:\n",
    "    subjectivities.append(doc._.subjectivity)\n",
    "df_filtered['subjectivity'] = subjectivities"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Week 2 Distant Reading.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
