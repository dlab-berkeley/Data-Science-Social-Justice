{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "239ea8b1-4081-41b8-b972-bb8262533cb5",
   "metadata": {},
   "source": [
    "# Data Science for Social Justice Workshop: Word Embeddings and Language Bias - PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5132915b-031e-4a0b-a9e5-d2b399864384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "from gensim.models import Word2Vec\n",
    "import multiprocessing\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a4f7a0-8d78-44c0-8b27-5015178a2ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace this with your own pickle file!\n",
    "with open('../../data/YOUR_FILE.pickle', 'rb') as f:\n",
    "    posts = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b980b67-4391-481f-bd2e-781b7255ed71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split into lists of words for Word2Vec\n",
    "post_list = [post.split() for post in posts]\n",
    "post_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d88d4c-38a4-4ea3-a61e-7253b389ee8a",
   "metadata": {
    "id": "Wk2mxX1HZOpk"
   },
   "source": [
    "# Constructing a Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37503c4-1a2b-4a52-942a-a61c8a47ae0c",
   "metadata": {
    "id": "sQq117-pZOpl"
   },
   "outputs": [],
   "source": [
    "cores = multiprocessing.cpu_count() # Number of cores at your disposal\n",
    "\n",
    "n_features = 300     # Word vector dimensionality (how many features each word will be given)\n",
    "min_word_count = 10  # Minimum word count to be taken into account\n",
    "n_workers = cores    # Number of threads to run in parallel (equal to your amount of cores)\n",
    "window = 5           # Context window size\n",
    "downsampling = 1e-2  # Downsample setting for frequent words\n",
    "seed = 1             # Seed for the random number generator (to create reproducible results)\n",
    "sg = 1               # Skip-gram = 1, CBOW = 0\n",
    "epochs = 20          # Number of iterations over the corpus\n",
    "\n",
    "model = Word2Vec(\n",
    "    sentences=post_list,\n",
    "    workers=n_workers,\n",
    "    vector_size=n_features,\n",
    "    min_count=min_word_count,\n",
    "    window=window,\n",
    "    sample=downsampling,\n",
    "    seed=seed,\n",
    "    sg=sg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27457c86-4324-4a78-a2e1-192716a4d21a",
   "metadata": {
    "id": "JRX-lzwSzFI5"
   },
   "outputs": [],
   "source": [
    "# Save the model to disk\n",
    "model.save('../../data/embeddings.emb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37eb26f-924e-41b5-ae2e-c6d6817b3959",
   "metadata": {
    "id": "SZMDwWBuGTn7"
   },
   "outputs": [],
   "source": [
    "# Load the model from disk\n",
    "model = Word2Vec.load('../../data/embeddings.emb')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8032c3-401d-467d-90ad-9f6ee5285331",
   "metadata": {
    "id": "wWQC4S9IZOpu"
   },
   "source": [
    "How many terms are in your vocabulary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b998475-0cee-4a9d-87fa-4397d2bf4e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model.wv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14436cc-0c76-429e-a080-01b8806d953a",
   "metadata": {},
   "source": [
    "# Word Similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01c7e85-d9a1-49b2-96aa-f83a860edb80",
   "metadata": {
    "id": "v1HVouFqZOp0"
   },
   "outputs": [],
   "source": [
    "def get_most_similar_terms(model, token, topn=20):\n",
    "    \"\"\"Look up the top N most similar terms to the token.\"\"\"\n",
    "    for word, similarity in model.wv.most_similar(positive=[token], topn=topn):\n",
    "        print(f\"{word}: {round(similarity, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e31bbf3-9190-451e-a842-21c5a6720530",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 304,
     "status": "ok",
     "timestamp": 1639950052918,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhuBmxDvW5I_LJfZtwlPqMFD8QGLVPP3skvpkTnuQ=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -60
    },
    "id": "CDyV-ntGZOp3",
    "outputId": "d72277e1-e4e1-451d-e706-70b7fb7ebb02"
   },
   "outputs": [],
   "source": [
    "get_most_similar_terms(model, 'CHOOSE_WORD')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed4fc94-dbb9-4384-8eb3-edacfb1e1f62",
   "metadata": {},
   "source": [
    "# Visualizing High Dimensional Spaces with $t$-SNE\n",
    "\n",
    "Change `words` to include words you are interested in for your data (make sure they appear in your dataset!) in order to visualize their relations. You can make this list as long or short as you want.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd556fa-8fee-49bc-9589-05f9d7187914",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['WORD1', 'WORD2', 'WORD3', 'WORD4','WORD5','WORD6','WORD7','WORD8']\n",
    "\n",
    "# Extract the word vectors\n",
    "word_vectors = np.array([model.wv[word] for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab163662-038f-4a22-91c6-d3b71c5c5937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you get an ImportError in the line tsne=TSNE(), you might need to install scikit-learn:\n",
    "# %pip install -U scikit-learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6792fda-4bd6-414a-b275-75bf3352a80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce dimensionality using t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=2, perplexity=2)\n",
    "reduced_vectors = tsne.fit_transform(word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e15576-3c70-4d8b-962b-46f99a86c540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the t-SNE vectors\n",
    "words_df = pd.DataFrame(reduced_vectors,\n",
    "                            index=pd.Index([word for word in words]),\n",
    "                            columns=['x', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c47ac40-66e9-4087-afa6-1c445a2daea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.models import LabelSet\n",
    "\n",
    "# Add our DataFrame as a ColumnDataSource for Bokeh\n",
    "plot_data = ColumnDataSource(words_df)\n",
    "\n",
    "# Create the plot and configure the title, dimensions, and tools\n",
    "tsne_plot = figure(title='t-SNE Word Embeddings')\n",
    "\n",
    "# Add a hover tool to display words on roll-over\n",
    "tsne_plot.add_tools(HoverTool(tooltips='@index'))\n",
    "\n",
    "# Draw the words as circles on the plot\n",
    "tsne_plot.circle('x', 'y',\n",
    "                 source=plot_data,\n",
    "                 color='blue',\n",
    "                 size=10,\n",
    "                 hover_line_color='black')\n",
    "\n",
    "# Add labels to the points\n",
    "labels = LabelSet(x='x', y='y', text='index', level='glyph',\n",
    "                  x_offset=5, y_offset=5, source=plot_data,\n",
    "                  render_mode='canvas')\n",
    "tsne_plot.add_layout(labels)\n",
    "\n",
    "# Engage!\n",
    "show(tsne_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72f6950-9ce6-464a-8e6b-5f36b980c134",
   "metadata": {},
   "source": [
    "Now let's use $t$-SNE to take **all** the word vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bb6125-b1bf-49ef-9ac2-a47e0f471b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(init='pca', learning_rate='auto')\n",
    "X_tsne = tsne.fit_transform(model.wv.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa375c4-1f59-44de-a91a-fbcf3a9ae63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the t-SNE vectors\n",
    "tsne_df = pd.DataFrame(X_tsne,\n",
    "                            index=pd.Index(model.wv.index_to_key),\n",
    "                            columns=['x', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9437ab84-d63b-4635-be70-932ed5d3ab73",
   "metadata": {
    "id": "jd60bqFxe9z1"
   },
   "outputs": [],
   "source": [
    "# Create some filepaths to save our model\n",
    "tsne_path = '../../data/tsne_model'\n",
    "tsne_df_path = '../../data/tsne_df.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87100b48-bd49-47ae-8272-be125f75f3ae",
   "metadata": {
    "id": "QBe7lNE3e7oQ"
   },
   "outputs": [],
   "source": [
    "# Save to disk\n",
    "with open(tsne_path, 'wb') as f:\n",
    "    pickle.dump(X_tsne, f)\n",
    "\n",
    "tsne_df.to_pickle(tsne_df_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af164a0-0697-4f73-9cd5-55fde33120d8",
   "metadata": {},
   "source": [
    "Here's a convenient code block to load this data, to start from this point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1934629a-c3c4-4c01-808e-00e6bbd81aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tsne_path, 'rb') as f:\n",
    "    X_tsne = pickle.load(f)\n",
    "    \n",
    "tsne_df = pd.read_pickle(tsne_df_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220e4008-202a-431e-a692-8b08c3a43f90",
   "metadata": {},
   "source": [
    "Visualize with bokeh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f96089c-a595-4eba-8eb8-c4af5d073574",
   "metadata": {
    "id": "9AE4-OrmKmKG"
   },
   "outputs": [],
   "source": [
    "import bokeh\n",
    "from bokeh.plotting import figure, show, output_notebook\n",
    "from bokeh.models import HoverTool, ColumnDataSource\n",
    "\n",
    "output_notebook()\n",
    "bokeh.io.output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed097c8d-6d08-480d-8f0d-c63504529dce",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 817
    },
    "executionInfo": {
     "elapsed": 747,
     "status": "ok",
     "timestamp": 1640017607454,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhuBmxDvW5I_LJfZtwlPqMFD8QGLVPP3skvpkTnuQ=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -60
    },
    "id": "myJtActVdjn4",
    "outputId": "5f283a90-c0f4-4c31-88ea-5f7bfa6917ee",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add our DataFrame as a ColumnDataSource for Bokeh\n",
    "plot_data = ColumnDataSource(tsne_df)\n",
    "\n",
    "# Create the plot and configure the title, dimensions, and tools\n",
    "tsne_plot = figure(title='t-SNE Word Embeddings')\n",
    "\n",
    "# Add a hover tool to display words on roll-over\n",
    "tsne_plot.add_tools(HoverTool(tooltips='@index') )\n",
    "\n",
    "# Draw the words as circles on the plot\n",
    "tsne_plot.circle('x', 'y',\n",
    "                 source=plot_data,\n",
    "                 color='blue',\n",
    "                 line_alpha=0.2,\n",
    "                 fill_alpha=0.1,\n",
    "                 size=10,\n",
    "                 hover_line_color='black')\n",
    "\n",
    "# Engage!\n",
    "show(tsne_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bc6563-a2b7-430e-b5f1-94bebd7b975f",
   "metadata": {},
   "source": [
    "# Language Biases and Word Embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36bcc0a-09ca-48ba-b2d4-63569e82934c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import function to calculate biased words\n",
    "from utils import calculate_biased_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb562757-1cf9-4238-bc31-af332a29afae",
   "metadata": {},
   "source": [
    "Change these words to words that are illustrative of a **target concept**, organized in some kind of binary. Think of \"male\" and \"female\", \"Islam\" and \"Christianity\", or \"career\" and \"family\". For some examples of target sets that have been used in the literature, check the bottom of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca51a4ab-b3f4-4cce-a19c-74465c5e03c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "target1 = ['WORD1' , 'WORD2' , 'WORD3' , 'WORD4' , 'WORD5' , 'WORD6' , 'WORD7' , 'WORD8']\n",
    "target2 = ['WORD1' , 'WORD2' , 'WORD3' , 'WORD4' , 'WORD5' , 'WORD6' , 'WORD7' , 'WORD8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659d51a9-c0fd-4492-849e-96c8cc3edd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load('../../data/embeddings.emb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83da73ef-e7fe-4494-bc0d-62e83cbfe7bd",
   "metadata": {
    "executionInfo": {
     "elapsed": 11526,
     "status": "ok",
     "timestamp": 1647303428120,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhuBmxDvW5I_LJfZtwlPqMFD8QGLVPP3skvpkTnuQ=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": 300
    },
    "id": "SIzdtQV5rQlh",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[b1, b2] = calculate_biased_words(model, target1, target2, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50fa880-09a7-4169-8991-b6cb17a7b7aa",
   "metadata": {
    "id": "LJpg5BDydlYT"
   },
   "source": [
    "Let's print some biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12349d29-3b4d-4865-8428-ee0ceff24d0f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 191,
     "status": "ok",
     "timestamp": 1647303438347,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhuBmxDvW5I_LJfZtwlPqMFD8QGLVPP3skvpkTnuQ=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": 300
    },
    "id": "qc-9g8BErQll",
    "outputId": "93aa1d97-e9ad-4f17-9ce3-bef7d4079209"
   },
   "outputs": [],
   "source": [
    "print('Biased words towards target set 1')\n",
    "print([word for word in b1.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca33e41e-bfc7-4be5-80bb-6e83f181c452",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Biased words towards target set 2')\n",
    "print([word for word in b2.keys()] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc812af-422c-446e-ad00-1cf743155101",
   "metadata": {
    "id": "Zpk0lx2xplMf"
   },
   "source": [
    "## Visualizing Biases using $t$-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7754fedb-2f16-450c-9d95-c12280b546e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b669be3e-2071-4714-a4c1-ffae8164579d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tsne_path, 'rb') as f:\n",
    "    X_tsne = pickle.load(f)\n",
    "    \n",
    "tsne_df = pd.read_pickle(tsne_df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af85d3bf-e8cb-4449-af36-bb3b729597fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert biased term keys to arrays\n",
    "target1_idx = np.array([model.wv.key_to_index[key] for key in b1.keys()])\n",
    "target2_idx = np.array([model.wv.key_to_index[key] for key in b2.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2494d6be-2276-4692-9e5f-e5d42655fbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find t-sne values for the biased sets\n",
    "X_target1 = X_tsne[target1_idx]\n",
    "X_target2 = X_tsne[target2_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6cea48-7caf-4f8b-aeed-bd4cc8c2458c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import show, output_notebook, output_file\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.models import ColumnDataSource, LabelSet\n",
    "\n",
    "# Set up the Bokeh plot\n",
    "output_notebook()\n",
    "\n",
    "p = figure()\n",
    "\n",
    "# Create ColumnDataSource for X_target1 (blue)\n",
    "source1 = ColumnDataSource(data=dict(x=X_target1[:, 0], y=X_target1[:, 1], label=[model.wv.index_to_key[idx] for idx in target1_idx]))\n",
    "\n",
    "# Create ColumnDataSource for X_target2 (red)\n",
    "source2 = ColumnDataSource(data=dict(x=X_target2[:, 0], y=X_target2[:, 1], label=[model.wv.index_to_key[idx] for idx in target2_idx]))\n",
    "\n",
    "# Add scatter plot for X_target1 (blue)\n",
    "p.scatter(x='x', y='y', color='blue', size=8, source=source1)\n",
    "\n",
    "# Add scatter plot for X_target2 (red)\n",
    "p.scatter(x='x', y='y', color='red', size=8, source=source2)\n",
    "\n",
    "# Add labels for X_target1\n",
    "labels1 = LabelSet(x='x', y='y', text='label', x_offset=6, y_offset=3, source=source1, render_mode='canvas')\n",
    "p.add_layout(labels1)\n",
    "\n",
    "# Add labels for X_target2\n",
    "labels2 = LabelSet(x='x', y='y', text='label', x_offset=6, y_offset=3, source=source2, render_mode='canvas')\n",
    "p.add_layout(labels2)\n",
    "\n",
    "# Show the plot\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60527010-8a4e-477a-8513-c51c489bd4b5",
   "metadata": {
    "id": "riINX9wVyFRJ",
    "tags": []
   },
   "source": [
    "## Existing Target Sets\n",
    "\n",
    "Here are some other target sets that have been previously used in the literature:\n",
    "\n",
    "* *Gender target sets taken from Nosek, Banaji, and Greenwald 2002.*\n",
    "    - Female: `sister, female, woman, girl, daughter, she, hers, her`.\n",
    "    - Male: `brother, male, man, boy, son, he, his, him`.\n",
    "* *Religion target sets taken from Garg et al. 2018.*\n",
    "    - Islam: `allah, ramadan, turban, emir, salaam, sunni, koran, imam, sultan, prophet, veil, ayatollah, shiite, mosque, islam, sheik, muslim, muhammad`.\n",
    "    - Christianity: `baptism, messiah, catholicism, resurrection, christianity, salva-tion, protestant, gospel, trinity, jesus, christ, christian, cross,catholic, church`.\n",
    "* *Racial target sets taken from Garg et al. 2017*\n",
    "    - White last names: `harris, nelson, robinson, thompson, moore, wright, anderson, clark, jackson, taylor, scott, davis, allen, adams, lewis, williams, jones, wilson, martin, johnson`.\n",
    "    - Hispanic last names: `ruiz, alvarez, vargas, castillo, gomez, soto,gonzalez, sanchez, rivera, mendoza, martinez, torres, ro-driguez, perez, lopez, medina, diaz, garcia, castro, cruz`.\n",
    "    - Asian last names: `cho, wong, tang, huang, chu, chung, ng,wu, liu, chen, lin, yang, kim, chang, shah, wang, li, khan,singh, hong`.\n",
    "    - Russian last names: `gurin, minsky, sokolov, markov, maslow, novikoff, mishkin, smirnov, orloff, ivanov, sokoloff, davidoff, savin, romanoff, babinski, sorokin, levin, pavlov, rodin, agin`.\n",
    "* *Career/family target sets taken from Garg et al. 2018.*\n",
    "    - Career: `executive, management, professional, corporation, salary, office, business, career`.\n",
    "    - Family: `home, parents, children, family, cousins, marriage, wedding, relatives.Math: math, algebra, geometry, calculus, equations, computation, numbers, addition`.\n",
    "* *Arts/Science target sets taken from Garg et al. 2018.*\n",
    "    - Arts: `poetry, art, sculpture, dance, literature, novel, symphony, drama`.\n",
    "    - Science: `science, technology, physics, chemistry, Einstein, NASA, experiment, astronomy`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlab",
   "language": "python",
   "name": "dlab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
