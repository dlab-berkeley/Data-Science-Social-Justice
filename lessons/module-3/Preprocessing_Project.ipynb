{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WClw_VPOmwXd"
   },
   "source": [
    "# Data Science for Social Justice Workshop: Preprocessing â€“ Project Notebook\n",
    "\n",
    "Use this notebook for carrying out the analyses from the workshop notebook on your own subreddit data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Icons Used in This Notebook\n",
    "ðŸ’­ **Reflection**: Reflecting on ethical implications, biases, and social impact in data science.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the Data\n",
    "\n",
    "Put your data in the `data` folder of this repo and replace `YOUR_FILE.csv` below with the name of your file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2525,
     "status": "ok",
     "timestamp": 1647459522220,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhuBmxDvW5I_LJfZtwlPqMFD8QGLVPP3skvpkTnuQ=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": 300
    },
    "id": "bIB1SsShP9iL",
    "outputId": "ab2ec235-c74b-4f81-f7dc-d41825605164"
   },
   "outputs": [],
   "source": [
    "# Import the pandas package\n",
    "import pandas as pd \n",
    "\n",
    "# Replace this with your own file!\n",
    "df = pd.read_csv('../../data/YOUR_FILE.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the shape, first rows, and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 773
    },
    "executionInfo": {
     "elapsed": 313,
     "status": "ok",
     "timestamp": 1647459542614,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhuBmxDvW5I_LJfZtwlPqMFD8QGLVPP3skvpkTnuQ=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": 300
    },
    "id": "TkI-FuY2mwX6",
    "outputId": "87472d59-a42b-4a76-ff02-3aaa0f474e78",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1639763489064,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhuBmxDvW5I_LJfZtwlPqMFD8QGLVPP3skvpkTnuQ=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -60
    },
    "id": "7oZfTJi2rA6Z",
    "outputId": "88d7211b-3e6e-447c-87da-fcffadc71a58"
   },
   "outputs": [],
   "source": [
    "# This allows you to quickly see which columns you have\n",
    "list(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ’­ Reflection\n",
    "\n",
    "Take some time to look at the reddit community you have chosen with your teammates. If it no longer exists, look at some of the posts in your DataFrame. Discuss the following questions:\n",
    "\n",
    "- What kinds of norms and values does this community seem to be organized around?\n",
    "- Does the community include a FAQ or Wiki page that explain rules for interaction among members? What are these rules?\n",
    "- What are the most popular posts of all time? Do they have something in common?\n",
    "- Are there dissenting voices when it comes to these norms? How do others respond to them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing columns and rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop some columns\n",
    "df = df.drop(['self', 'url', 'subreddit', 'augmented_at', 'augmented_count'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: If you are preprocessing a **comments** file, the `selftext` column is called `body`! Make sure to replace this in the code below or you'll get a `KeyError`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select rows that don't have 'removed' or 'deleted' as the selftext\n",
    "df = df.loc[~df['selftext'].isin(['[removed]', '[deleted]' ]),:]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop null values in selftext\n",
    "df = df.dropna(subset=['selftext'])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save this cleaned-up dataframe in a new CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../../data/YOUR_FILE.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data with Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "from gensim.models.phrases import Phrases, Phraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1487,
     "status": "ok",
     "timestamp": 1647460151917,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhuBmxDvW5I_LJfZtwlPqMFD8QGLVPP3skvpkTnuQ=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": 300
    },
    "id": "qtrgcSZH4Rnb"
   },
   "outputs": [],
   "source": [
    "def preprocess(df, text_col='selftext'):\n",
    "    \"\"\"Preprocessing function to apply to a dataframe.\"\"\"\n",
    "    \n",
    "    for text in df[text_col]:\n",
    "        text = text.replace('\\n', '')\n",
    "        parsed = nlp(text, disable=[\"tok2vec\", \"ner\"])\n",
    "\n",
    "        # Gather lowercased, lemmatized tokens that are not punctuation, space, or digit\n",
    "        tokens = [\n",
    "            token.lemma_.lower() if token.lemma_ != '-PRON-'\n",
    "            else token.lower_ \n",
    "            for token in parsed \n",
    "            if not (token.is_punct or token.is_space or token.is_digit)\n",
    "        ]\n",
    "\n",
    "        # Remove specific lemmatizations, and words that are not nouns or adjectives\n",
    "        tokens = [\n",
    "            lemma\n",
    "            for lemma in tokens\n",
    "            if not lemma in [\"'s\",  \"â€™s\", \"â€™\"]\n",
    "        ]\n",
    "\n",
    "        # Remove stop words\n",
    "        tokens = [\n",
    "            token \n",
    "            for token in tokens \n",
    "            if token not in spacy.lang.en.stop_words.STOP_WORDS\n",
    "        ]\n",
    "\n",
    "        yield tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OjbgskrlDg16"
   },
   "outputs": [],
   "source": [
    "# This may take a while\n",
    "lemmas = [line for line in preprocess(df)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phrase modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 63667,
     "status": "ok",
     "timestamp": 1639846696683,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhuBmxDvW5I_LJfZtwlPqMFD8QGLVPP3skvpkTnuQ=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -60
    },
    "id": "MxeZ7mc9DeMj",
    "outputId": "a478fee9-f5b1-4562-e3a6-860e244e5719"
   },
   "outputs": [],
   "source": [
    "from gensim.models.phrases import Phrases, Phraser\n",
    "\n",
    "# Create bigram and trigram models\n",
    "bigram = Phrases(lemmas, min_count=10, threshold=100)\n",
    "trigram = Phrases(bigram[lemmas], min_count=10, threshold=50)  \n",
    "bigram_phraser = Phraser(bigram)\n",
    "trigram_phraser = Phraser(trigram)\n",
    "\n",
    "# Form trigrams\n",
    "trigrams = [trigram_phraser[bigram_phraser[doc]] for doc in lemmas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join each into a string\n",
    "trigrams_joined = [' '.join(trigram) for trigram in trigrams]\n",
    "trigrams_joined[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how many bigrams were identified by the parser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 216,
     "status": "ok",
     "timestamp": 1639846804300,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhuBmxDvW5I_LJfZtwlPqMFD8QGLVPP3skvpkTnuQ=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -60
    },
    "id": "xO4enOmLeXXi",
    "outputId": "921b6ce4-3390-4f90-ab13-e7bd4e0ce11f"
   },
   "outputs": [],
   "source": [
    "len(bigram_phraser.phrasegrams.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the first few bigrams identified in the model to check if they seem  appropriate. If not, you can play around with the parameters of the bigram model to adjust the sensitivity of the model (the values for `min_count` and `threshold` above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 346,
     "status": "ok",
     "timestamp": 1639846859895,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhuBmxDvW5I_LJfZtwlPqMFD8QGLVPP3skvpkTnuQ=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -60
    },
    "id": "uwySeLM4df97",
    "outputId": "0940755f-397e-48cc-ecdb-3558341cb7ae"
   },
   "outputs": [],
   "source": [
    "list(bigram_phraser.phrasegrams.keys())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at trigrams\n",
    "[trigram for trigram in list(trigram_phraser.phrasegrams.keys()) if trigram.count('_') == 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rVgem81TZWzu"
   },
   "source": [
    "## Saving data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to give this file a good name - e.g. indicate in the file name whether you have preprocessed submissions or comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../../data/YOUR_FILE.pickle', 'wb') as f:\n",
    "    # Save (or \"dump\") the object into the file\n",
    "    pickle.dump(trigrams_joined, f)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Week 1 Preprocessing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
